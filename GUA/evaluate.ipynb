{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import load_data, accuracy, normalize, load_polblogs_data\n",
    "from models import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    cuda = True\n",
    "    fastmode = False\n",
    "    seed = 20\n",
    "#     seed = 123\n",
    "    epochs = 200\n",
    "    lr = 0.01\n",
    "    weight_decay = 5e-4\n",
    "    hidden = 16\n",
    "    dropout = 0.5\n",
    "    pert_num = 20\n",
    "    L1 = 0.01\n",
    "    evaluate_mode = \"universal\"\n",
    "    dataset = \"cora\"\n",
    "    radius = 4\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"polblogs\":\n",
    "    tmp_adj, features, labels, idx_train, idx_test = load_polblogs_data()\n",
    "    print (sum(sum(tmp_adj)))\n",
    "    print (tmp_adj.shape)\n",
    "else:\n",
    "    _, features, labels, idx_train, idx_val, idx_test, tmp_adj  = load_data(args.dataset)\n",
    "\n",
    "num_classes = labels.max().item() + 1\n",
    "# tmp_adj = tmp_adj.toarray()\n",
    "\n",
    "adj = tmp_adj\n",
    "adj = np.eye(tmp_adj.shape[0]) + adj\n",
    "adj, _ = normalize(adj)\n",
    "adj = torch.from_numpy(adj.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=args.hidden,\n",
    "            nclass=num_classes,\n",
    "            dropout=args.dropout)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=args.lr, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    if args.dataset != \"polblogs\":\n",
    "        idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = Variable(adj, requires_grad=True)\n",
    "    output = model(features, x)\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "#     print ('output', output.size())\n",
    "#     print ('labels', labels.size())\n",
    "    loss_train.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if args.dataset != \"polblogs\": \n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    else:\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(adj_m):\n",
    "    model.eval()\n",
    "    output = model(features, adj_m)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = time.time()\n",
    "for epoch in range(args.epochs):\n",
    "    train(epoch)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "# torch.save(model, './cora_gcn.pth')\n",
    "# torch.save(model.state_dict(), 'cora_gcn.pkl')\n",
    "\n",
    "# Testing\n",
    "ori_output = test(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_perturb(input_adj, idx, perturb):\n",
    "    # (1-x)A + x(1-A)\n",
    "#     input_adj = input_adj.toarray()\n",
    "\n",
    "    x = np.zeros((input_adj.shape[0], input_adj.shape[1]))\n",
    "    x[idx] = perturb  \n",
    "    x[:,idx] = perturb\n",
    "#     print ('x', x[idx])\n",
    "\n",
    "    \n",
    "#     x += np.transpose(x) #change the idx'th row and column\n",
    "    x1 = np.ones((input_adj.shape[0], input_adj.shape[1])) - x\n",
    "#     print ('x1', x1[idx])\n",
    "    adj2 = np.ones((input_adj.shape[0], input_adj.shape[1])) - input_adj\n",
    "#     print ('adj2', adj2[idx])\n",
    "\n",
    "    for i in range(input_adj.shape[0]):      \n",
    "        adj2[i][i] = 0\n",
    "\n",
    "    perturbed_adj = np.multiply(x1, input_adj) + np.multiply(x, adj2)\n",
    "    return perturbed_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack(perturb):\n",
    "    res = []\n",
    "    # perturb = np.where(perturb>0.5, 1, 0)\n",
    "    print ('perturb', perturb)\n",
    "    new_pred = []\n",
    "    for i in range(num_classes):\n",
    "        new_pred.append(0)\n",
    "    for k in idx_test:\n",
    "#     for k in range(1):\n",
    "#         print ('test node', k)\n",
    "        innormal_x_p = add_perturb(tmp_adj, k, perturb)\n",
    "#         print ('the perturbed conn', sum(innormal_x_p[k]))\n",
    "#         innormal_x_p = np.where(innormal_x_p<0.5, 0, 1)\n",
    "\n",
    "#         diff = innormal_x_p[k] - tmp_adj[k]\n",
    "#         diff_idx = np.where(diff != 0 )\n",
    "        \n",
    "#         print ('diff_idx', diff_idx)\n",
    "    #     one_idx = np.where(innormal_x_p[k]==1)[0]\n",
    "    #     zero_idx = np.where(innormal_x_p[k]!=1)[0]\n",
    "    #     total_idx = one_idx.shape[0] + zero_idx.shape[0]\n",
    "    #     print ('total_idx', total_idx)\n",
    "    #     print ('one_idx', one_idx)\n",
    "    #     print ('corresponding perturb', perturb[one_idx])\n",
    "    #     print (innormal_x_p[k][one_idx])\n",
    "        x_p, degree_p = normalize(innormal_x_p + np.eye(tmp_adj.shape[0]))\n",
    "        x_p = torch.from_numpy(x_p.astype(np.float32))\n",
    "        x_p = x_p.cuda()\n",
    "        output = model(features, x_p)\n",
    "        new_pred[int(torch.argmax(output[k]))] += 1\n",
    "        if int(torch.argmax(output[k])) == int(torch.argmax(ori_output[k])):\n",
    "            res.append(0)\n",
    "            print ('node {} attack failed'.format(k))\n",
    "        else:\n",
    "            res.append(1)\n",
    "            print ('node {} attack succeed'.format(k))\n",
    "    fooling_rate = float(sum(res)/len(res))\n",
    "    print ('the current fooling rate is', fooling_rate)\n",
    "    return fooling_rate, new_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(pred):\n",
    "    h = 0\n",
    "    all_pred = sum(pred)\n",
    "    for i in range(num_classes):\n",
    "        Pi = pred[i]/all_pred\n",
    "        if Pi != 0:\n",
    "            h -=  Pi* math.log(Pi)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = []\n",
    "for i in range(num_classes):\n",
    "    new_pred.append(0)\n",
    "for k in idx_test:\n",
    "    new_pred[int(torch.argmax(ori_output[k]))] += 1\n",
    "entropy = calculate_entropy(new_pred)\n",
    "print ('the entropy is', entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the universal attack\n",
    "if args.evaluate_mode == \"universal\":\n",
    "    fool_res = []\n",
    "    p_times = []\n",
    "    all_entropy = []\n",
    "    for i in range(10):\n",
    "        perturb = np.array([float(line.rstrip('\\n')) for line in open('./perturbation_results/{1}_xi{2}_epoch100/perturbation_{1}_{0}.txt'.format(i, args.dataset, args.radius))])\n",
    "        perturb = np.where(perturb>0.5, 1, 0)\n",
    "        pt = np.where(perturb>0)[0]\n",
    "        if len(list(pt)) == 0:\n",
    "            fool_res.append(0)\n",
    "            p_times.append(0)\n",
    "            continue\n",
    "        print ('the perturbation is', pt)\n",
    "        res, new_pred = evaluate_attack(perturb)\n",
    "        print ('the prediction result is', new_pred)\n",
    "        entropy = calculate_entropy(new_pred)\n",
    "        fool_res.append(res)      \n",
    "        p_times.append(len(list(pt)))\n",
    "        print ('the perturbation times is', p_times)\n",
    "        print ('the fooling rates are', fool_res)\n",
    "        print ('the average fooling rates over 10 times of test is', sum(fool_res)/float(len(fool_res)))\n",
    "        print ('the entropy is', entropy)\n",
    "        all_entropy.append(entropy)\n",
    "    print ('all the entropy values are', all_entropy)\n",
    "    print ('the average entropy is', sum(all_entropy)/float(len(all_entropy)))\n",
    "        \n",
    "elif args.evaluate_mode == \"unlimitted_random\":\n",
    "    fool_res = []\n",
    "    p_times = []\n",
    "    for i in range(10):\n",
    "        perturb = np.random.rand(tmp_adj.shape[0])\n",
    "        perturb = np.where(perturb>0.5, 1, 0)\n",
    "        pt = np.where(perturb>0)[0]\n",
    "        print ('the perturbation is', len(list(pt)))\n",
    "        res = evaluate_attack(perturb)\n",
    "        fool_res.append(res)\n",
    "        \n",
    "        p_times.append(len(list(pt)))\n",
    "        print ('the perturbation times is', p_times)\n",
    "        print ('the fooling rates are', fool_res)\n",
    "        print ('the average fooling rates over 10 times of test is', sum(fool_res)/float(len(fool_res)))\n",
    "elif args.evaluate_mode == \"limitted_random\":\n",
    "    \n",
    "    perturb_times = 8\n",
    "    fool_res = []\n",
    "    p_times = []\n",
    "    for i in range(10):\n",
    "#         perturb = np.array([float(line.rstrip('\\n')) for line in open(\"perturbation.txt\")])\n",
    "#         perturb = np.where(perturb>0.5, 1, 0)\n",
    "#         perturb_times = sum(perturb)\n",
    "        perturb = np.zeros(adj.shape[1])\n",
    "        #the perturbation times of our universal perturbation\n",
    "        attack_index = list(np.random.choice(range(adj.shape[1]), perturb_times, replace = False))\n",
    "        perturb[attack_index] = 1\n",
    "        pt = np.where(perturb>0)[0]\n",
    "#         print ('the perturbation is', pt)\n",
    "        res = evaluate_attack(perturb)\n",
    "        fool_res.append(res)\n",
    "\n",
    "        p_times.append(len(list(pt)))\n",
    "        print ('the perturbation times is', p_times)\n",
    "        print ('the fooling rates are', fool_res)\n",
    "        print ('the average fooling rates over 10 times of test is', sum(fool_res)/float(len(fool_res)))\n",
    "\n",
    "    print ('the average fooling rate with {} perturbation times is'.format(perturb_times), sum(fool_res)/float(len(fool_res)))\n",
    "    \n",
    "elif args.evaluate_mode == \"victim_attak\":\n",
    "    #the perturbation times of our universal perturbation\n",
    "    perturb_time = 8 #set this equal to the ceil of the number of anchor nodes computed by universal attack\n",
    "    fool_res = []\n",
    "#     p_times = []\n",
    "    for k in range(num_classes):\n",
    "#     for k in range(4,6):\n",
    "        each_fool_res = []\n",
    "        idx = np.where(labels.cpu().numpy()==k)[0]\n",
    "#         for i in range(1):\n",
    "        for i in range(10):\n",
    "            attack_index = list(np.random.choice(idx, perturb_time, replace = False))\n",
    "            perturb = np.zeros(adj.shape[1])\n",
    "            perturb[attack_index] = 1\n",
    "            print ('perturbating by connecting to nodes of class', k)\n",
    "            res = evaluate_attack(perturb)\n",
    "            each_fool_res.append(res)\n",
    "            print ('the fooling rates of current class are', each_fool_res)\n",
    "            avg_asr = sum(each_fool_res)/float(len(each_fool_res))\n",
    "            print ('the average fooling rates over 10 times of test is', avg_asr)\n",
    "        fool_res.append(avg_asr)\n",
    "        print ('fool_res', fool_res)\n",
    "    print ('the avg asr by connecting to each class of nodes is', fool_res)\n",
    "        \n",
    "elif args.evaluate_mode == \"universal_delete\":   \n",
    "    \n",
    "    all_fool = []\n",
    "    for i in range(8, 9):\n",
    "        fool_res = []\n",
    "        for j in range(8):\n",
    "            perturb = np.array([float(line.rstrip('\\n')) for line in open('./perturbation_results/{1}_xi{2}_epoch100/perturbation_{1}_4.txt'.format(i, args.dataset, args.radius))])\n",
    "            perturb = np.where(perturb>0.5, 1, 0)\n",
    "            pt = np.where(perturb>0)[0]\n",
    "            a = list(np.random.choice(range(0, pt.shape[0]), i, replace = False))\n",
    "            perturb[pt[a]] = 0\n",
    "            pt = np.where(perturb>0)[0]\n",
    "            print ('the perturbation is', pt)\n",
    "            res, new_pred = evaluate_attack(perturb)\n",
    "            fool_res.append(res)      \n",
    "            print ('the fooling rates are', fool_res)\n",
    "            print ('the average fooling rates over 10 times of test is', sum(fool_res)/float(len(fool_res)))\n",
    "        all_fool.append(sum(fool_res)/float(len(fool_res)))\n",
    "          \n",
    "    print ('all the fooling rate is', all_fool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
